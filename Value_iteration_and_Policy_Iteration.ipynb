{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMZJU/2tCM8n9Oz7KncMiNA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/omaremad02/Markov-Decision-Process/blob/main/Value_iteration_and_Policy_Iteration.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This notebook includes implementations of the following algorithms:\n",
        "\n",
        "\n",
        "*   Value Iteration Algorithm\n",
        "*   Policy Iteration Algorithm\n",
        "\n",
        "The notebook also includes a test gridworld game where the two algorithms are implemented to extract the optimal policy for the agent and the optimal value function for each state.\n",
        "\n",
        "Below is the commented implementation where each section is in a seperate notebook.\n"
      ],
      "metadata": {
        "id": "47TabS3MJEXZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "n_Pz4SvuNJYH"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class gridworld:\n",
        "\n",
        "  def __init__(self, grid_size):\n",
        "    self.grid_size = grid_size\n",
        "    rewards = -(np.ones((grid_size, grid_size)))\n",
        "    rewards[0,2] = 10\n",
        "    self.rewards = rewards\n",
        "    self.actions = [\"U\", \"D\", \"L\", \"R\"]\n",
        "    self.action_prob = {'U': (0.8, 0.1, 0.1), 'D': (0.8, 0.1, 0.1),\n",
        "               'L': (0.8, 0.1, 0.1), 'R': (0.8, 0.1, 0.1)}\n",
        "\n",
        "  def next_state(self, state, action):\n",
        "    x, y = state\n",
        "    if action == 'U':\n",
        "        return [(x-1, y), (x, y-1), (x, y+1)]\n",
        "    elif action == 'D':\n",
        "        return [(x+1, y), (x, y-1), (x, y+1)]\n",
        "    elif action == 'L':\n",
        "        return [(x, y-1), (x-1, y), (x+1, y)]\n",
        "    elif action == 'R':\n",
        "        return [(x, y+1), (x-1, y), (x+1, y)]\n",
        "    return [state, state, state]\n",
        "\n",
        "  def is_valid(self, state):\n",
        "      x,y = state\n",
        "      return 0 <= x < self.grid_size and 0 <= y < self.grid_size"
      ],
      "metadata": {
        "id": "lPCl8oWkkt-A"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class agent_algorithms:\n",
        "  def __init__(self, grid: gridworld):\n",
        "    self.grid = grid\n",
        "    self.discount_factor = 0.99 # takes the future highly in consideration.\n",
        "\n",
        "\n",
        "  def value_iteration(self):\n",
        "    state_values = np.zeros((3,3)) #initializng the value function to zero.\n",
        "    while True:\n",
        "      delta = 0\n",
        "      for row in range(0,3):\n",
        "        for col in range(0,3):\n",
        "          max_value = float(\"-inf\")\n",
        "          for action in self.grid.actions:\n",
        "            value = 0\n",
        "            for prob, new_state in zip(self.grid.action_prob[action], self.grid.next_state((row,col), action)):\n",
        "              x1,y1 = new_state\n",
        "              if self.grid.is_valid(new_state):\n",
        "                value += prob * self.discount_factor * state_values[x1,y1]\n",
        "              else:\n",
        "                value += prob * self.discount_factor * state_values[row,col]\n",
        "              value += self.grid.rewards[row,col]\n",
        "            if value > max_value:\n",
        "              state_values[row,col] = value\n",
        "              delta = max(delta, abs(value - state_values[row, col]))\n",
        "      if delta < 1e-4:\n",
        "            break\n",
        "    return state_values\n",
        "\n",
        "  def extract_policy(self, state_values):\n",
        "    policy = np.empty((3, 3), dtype=str)\n",
        "    for row in range(3):\n",
        "        for col in range(3):\n",
        "            max_value = float(\"-inf\")\n",
        "            best_action = None\n",
        "            for action in self.grid.actions:\n",
        "                value = 0\n",
        "                for prob, new_state in zip(self.grid.action_prob[action], self.grid.next_state((row,col), action)):\n",
        "                    x1, y1 = new_state\n",
        "                    if self.grid.is_valid(new_state):\n",
        "                        value += prob * (self.discount_factor * state_values[x1, y1])\n",
        "                    else:\n",
        "                        value += prob * (self.discount_factor * state_values[row, col])\n",
        "                    value+= self.grid.rewards[row, col]\n",
        "                if value > max_value:\n",
        "                    max_value = value\n",
        "                    best_action = action\n",
        "            policy[row, col] = best_action\n",
        "    return policy"
      ],
      "metadata": {
        "id": "Ub0XCnVDQLtd"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test"
      ],
      "metadata": {
        "id": "ZIIhGQVZx8Q0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reward_list = [100,3,0,-3]\n",
        "grid = gridworld(grid_size= 3)\n",
        "for i in range(4):\n",
        "  grid.rewards[0,0] = reward_list[i]\n",
        "  agent = agent_algorithms(grid)\n",
        "  print(f\"State values when r = {reward_list[i]}\")\n",
        "  result = agent.value_iteration()\n",
        "  policy = agent.extract_policy(result)\n",
        "  print(result)\n",
        "  print()\n",
        "  print(policy)\n",
        "  print()\n",
        "  print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OURKWnsEx9gq",
        "outputId": "848ab520-19a3-4661-89ca-c723f33da8c1"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "State values when r = 100\n",
            "[[358.7825073   25.15314214  77.62951928]\n",
            " [ 32.51946822  -0.50983893   8.07629415]\n",
            " [  1.76496803  -3.26683906  -6.51799654]]\n",
            "\n",
            "[['L' 'L' 'U']\n",
            " ['U' 'L' 'U']\n",
            " ['U' 'L' 'U']]\n",
            "\n",
            "\n",
            "State values when r = 3\n",
            "[[10.76347522 -2.47201665 57.87009329]\n",
            " [-1.93441595 -3.24472965  2.85531541]\n",
            " [-4.1282869  -4.05353689 -8.38854082]]\n",
            "\n",
            "[['L' 'R' 'R']\n",
            " ['U' 'R' 'U']\n",
            " ['U' 'U' 'U']]\n",
            "\n",
            "\n",
            "State values when r = 0\n",
            "[[ 0.         -3.326403   57.25897703]\n",
            " [-3.         -3.3293139   2.69384184]\n",
            " [-4.31055252 -4.07786775 -8.4463927 ]]\n",
            "\n",
            "[['L' 'R' 'R']\n",
            " ['U' 'R' 'U']\n",
            " ['U' 'U' 'U']]\n",
            "\n",
            "\n",
            "State values when r = -3\n",
            "[[-10.76347522  -4.18078935  56.64786076]\n",
            " [ -4.06558405  -3.41389815   2.53236827]\n",
            " [ -4.49281814  -4.10219861  -8.50424459]]\n",
            "\n",
            "[['D' 'R' 'R']\n",
            " ['R' 'R' 'U']\n",
            " ['U' 'U' 'U']]\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dopp0Et2zh9I"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}