{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNbl5gkk0XynJfXsM0cowgn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/omaremad02/Markov-Decision-Process/blob/main/Value_iteration_and_Policy_Iteration.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This notebook includes implementations of the following algorithms:\n",
        "\n",
        "\n",
        "*   Value Iteration Algorithm\n",
        "*   Policy Iteration Algorithm\n",
        "\n",
        "The notebook also includes a test gridworld game where the two algorithms are implemented to extract the optimal policy for the agent and the optimal value function for each state.\n",
        "\n",
        "Below is the commented implementation where each section is in a seperate notebook.\n"
      ],
      "metadata": {
        "id": "47TabS3MJEXZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "n_Pz4SvuNJYH"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class gridworld:\n",
        "\n",
        "  def __init__(self, grid_size):\n",
        "    self.grid_size = grid_size\n",
        "    rewards = -(np.ones((grid_size, grid_size)))\n",
        "    rewards[0,2] = 10\n",
        "    self.rewards = rewards\n",
        "    self.actions = [\"U\", \"D\", \"L\", \"R\"]\n",
        "    self.action_prob = {'U': (0.8, 0.1, 0.1), 'D': (0.8, 0.1, 0.1),\n",
        "               'L': (0.8, 0.1, 0.1), 'R': (0.8, 0.1, 0.1)}\n",
        "\n",
        "  def next_state(self, state, action):\n",
        "    x, y = state\n",
        "    if action == 'U':\n",
        "        return [(x-1, y), (x, y-1), (x, y+1)]\n",
        "    elif action == 'D':\n",
        "        return [(x+1, y), (x, y-1), (x, y+1)]\n",
        "    elif action == 'L':\n",
        "        return [(x, y-1), (x-1, y), (x+1, y)]\n",
        "    elif action == 'R':\n",
        "        return [(x, y+1), (x-1, y), (x+1, y)]\n",
        "    return [state, state, state]\n",
        "\n",
        "  def is_valid(self, state):\n",
        "      x,y = state\n",
        "      return 0 <= x < self.grid_size and 0 <= y < self.grid_size"
      ],
      "metadata": {
        "id": "lPCl8oWkkt-A"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class agent_algorithms:\n",
        "  def __init__(self, grid: gridworld):\n",
        "    self.grid = grid\n",
        "    self.discount_factor = 0.99 # takes the future highly in consideration.\n",
        "\n",
        "\n",
        "  def value_iteration(self):\n",
        "    state_values = np.zeros((3,3)) #initializng the value function to zero.\n",
        "    while True:\n",
        "      delta = 0\n",
        "      for row in range(0,3):\n",
        "        for col in range(0,3):\n",
        "          max_value = float(\"-inf\")\n",
        "          for action in self.grid.actions:\n",
        "            value = 0\n",
        "            for prob, new_state in zip(self.grid.action_prob[action], self.grid.next_state((row,col), action)):\n",
        "              x1,y1 = new_state\n",
        "              if self.grid.is_valid(new_state):\n",
        "                value += prob * self.discount_factor * state_values[x1,y1]\n",
        "              else:\n",
        "                value += prob * self.discount_factor * state_values[row,col]\n",
        "            if value > max_value:\n",
        "              state_values[row,col] = value\n",
        "              delta = max(delta, abs(value - state_values[row, col]))\n",
        "      if delta < 1e-4:\n",
        "            break\n",
        "    return state_values"
      ],
      "metadata": {
        "id": "Ub0XCnVDQLtd"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6hvfPBQ4Qa2D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test"
      ],
      "metadata": {
        "id": "ZIIhGQVZx8Q0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reward_list = [100,3,0,-3]\n",
        "grid = gridworld(grid_size= 3)\n",
        "for i in range(4):\n",
        "  grid.rewards[0,0] = reward_list[i]\n",
        "  agent = agent_algorithms(grid)\n",
        "  result = agent.value_iteration()\n",
        "  print(result)\n",
        "  print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OURKWnsEx9gq",
        "outputId": "4d3d0ee1-ed83-4e60-9413-dc10f0d85a5a"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "\n",
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "\n",
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "\n",
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dopp0Et2zh9I"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}